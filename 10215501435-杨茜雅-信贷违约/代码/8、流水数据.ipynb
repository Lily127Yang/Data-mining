{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、处理流水数据（加五个特征）'avg_discount', 'avg_paid', 'avg_order', 'avg_balance', 'avg_advance'\n",
    "##### 以下是相关的训练和测试文件"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 训练1/train_both_his2.txt\n",
    "###### 训练1/train_combined_with_merchant_info_with_store_count.txt\n",
    "###### 测试1/test_both_his2.txt\n",
    "###### 测试1/test_combined_with_merchant_info_with_store_count.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 查看数据是否充足"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_both_his2.txt: Total Merchant IDs: 166, Missing in clean.txt: 0\n",
      "train_combined_with_merchant_info_with_store_count.txt: Total Merchant IDs: 942, Missing in clean.txt: 0\n",
      "test_both_his2.txt: Total Merchant IDs: 67, Missing in clean.txt: 0\n",
      "test_combined_with_merchant_info_with_store_count.txt: Total Merchant IDs: 421, Missing in clean.txt: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 文件路径\n",
    "train_both_path = '训练1/train_both_his2.txt'\n",
    "train_combined_path = '训练1/train_combined_with_merchant_info_with_store_count.txt'\n",
    "test_both_path = '测试1/test_both_his2.txt'\n",
    "test_combined_path = '测试1/test_combined_with_merchant_info_with_store_count.txt'\n",
    "clean_data_path = '流水数据/clean.txt'\n",
    "\n",
    "# 读取流水数据中的 merchant_id\n",
    "clean_data = pd.read_csv(clean_data_path)\n",
    "clean_merchant_ids = set(clean_data['merchant_id'].unique())\n",
    "\n",
    "# 读取并检查文件中的 merchant_id\n",
    "def check_merchant_ids(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    merchant_ids = set(data['merchant_id'].unique())\n",
    "    total_ids = len(merchant_ids)\n",
    "    missing_ids = merchant_ids - clean_merchant_ids\n",
    "    missing_count = len(missing_ids)\n",
    "    return total_ids, missing_count\n",
    "\n",
    "# 检查每个文件\n",
    "train_both_total, train_both_missing = check_merchant_ids(train_both_path)\n",
    "train_combined_total, train_combined_missing = check_merchant_ids(train_combined_path)\n",
    "test_both_total, test_both_missing = check_merchant_ids(test_both_path)\n",
    "test_combined_total, test_combined_missing = check_merchant_ids(test_combined_path)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"train_both_his2.txt: Total Merchant IDs: {train_both_total}, Missing in clean.txt: {train_both_missing}\")\n",
    "print(f\"train_combined_with_merchant_info_with_store_count.txt: Total Merchant IDs: {train_combined_total}, Missing in clean.txt: {train_combined_missing}\")\n",
    "print(f\"test_both_his2.txt: Total Merchant IDs: {test_both_total}, Missing in clean.txt: {test_both_missing}\")\n",
    "print(f\"test_combined_with_merchant_info_with_store_count.txt: Total Merchant IDs: {test_combined_total}, Missing in clean.txt: {test_combined_missing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "流水数据 'clean.txt' 中不同的 merchant_id 数量: 1586\n",
      "四个文件中不同的 merchant_id 总数: 1586\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 文件路径\n",
    "clean_data_path = '流水数据/clean.txt'\n",
    "train_both_path = '训练1/train_both_his2.txt'\n",
    "train_combined_path = '训练1/train_combined_with_merchant_info_with_store_count.txt'\n",
    "test_both_path = '测试1/test_both_his2.txt'\n",
    "test_combined_path = '测试1/test_combined_with_merchant_info_with_store_count.txt'\n",
    "\n",
    "# 读取流水数据中的 merchant_id\n",
    "clean_data = pd.read_csv(clean_data_path)\n",
    "clean_merchant_ids = set(clean_data['merchant_id'].unique())\n",
    "print(f\"流水数据 'clean.txt' 中不同的 merchant_id 数量: {len(clean_merchant_ids)}\")\n",
    "\n",
    "# 读取并汇总所有文件中的 merchant_id\n",
    "files = [train_both_path, train_combined_path, test_both_path, test_combined_path]\n",
    "all_merchant_ids = set()\n",
    "\n",
    "for file in files:\n",
    "    data = pd.read_csv(file)\n",
    "    all_merchant_ids.update(data['merchant_id'].unique())\n",
    "\n",
    "print(f\"四个文件中不同的 merchant_id 总数: {len(all_merchant_ids)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 发现在四个文件中相同merchant_id的贷款申请日期一定是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 merchant_id 的 apply_date 都相同。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 定义文件路径列表\n",
    "file_paths = [\n",
    "    '训练1/train_both_his2.txt',\n",
    "    '训练1/train_combined_with_merchant_info_with_store_count.txt',\n",
    "    '测试1/test_both_his2.txt',\n",
    "    '测试1/test_combined_with_merchant_info_with_store_count.txt'\n",
    "]\n",
    "\n",
    "# 合并所有文件中的 merchant_id 和 apply_date\n",
    "all_data = pd.DataFrame()\n",
    "for path in file_paths:\n",
    "    data = pd.read_csv(path, usecols=['merchant_id', 'apply_date'])\n",
    "    all_data = pd.concat([all_data, data], ignore_index=True)\n",
    "\n",
    "# 转换 apply_date 到 datetime 类型\n",
    "all_data['apply_date'] = pd.to_datetime(all_data['apply_date'], format='%Y%m%d', errors='coerce')\n",
    "\n",
    "# 分组 by merchant_id, 检查是否有多个不同的 apply_date\n",
    "grouped = all_data.groupby('merchant_id')['apply_date'].nunique()\n",
    "\n",
    "# 找到有多个不同 apply_date 的 merchant_id\n",
    "multiple_dates = grouped[grouped > 1]\n",
    "\n",
    "if not multiple_dates.empty:\n",
    "    print(f\"存在 {len(multiple_dates)} 个 merchant_id 有多个不同的 apply_date。\")\n",
    "    print(\"其中一些包括：\")\n",
    "    print(multiple_dates.head())  # 显示一些示例\n",
    "else:\n",
    "    print(\"所有 merchant_id 的 apply_date 都相同。\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 以某一个merchant_id为例，发现流水记录中存在申请日期后的交易记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merchant_id: 934378057859389\n",
      "最晚申请日期: 2018-06-08 00:00:00\n",
      "有效日期开始: 2017-12-10 00:00:00\n",
      "符合条件的流水记录数: 3628\n",
      "总流水记录数: 4031\n",
      "符合条件的记录详情:\n",
      "                pt  paid_amount\n",
      "657     2018-04-22         5200\n",
      "1707    2018-04-22         2100\n",
      "2964    2018-04-22         2800\n",
      "3040    2018-04-22         2200\n",
      "3695    2018-04-22         1300\n",
      "...            ...          ...\n",
      "3418933 2018-04-14         1300\n",
      "3420574 2018-04-17         1300\n",
      "3421592 2018-04-18         1100\n",
      "3421750 2018-04-18         1700\n",
      "3421859 2018-04-18         1600\n",
      "\n",
      "[3628 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# 加载训练数据，以确保我们得到正确的 apply_date\n",
    "file_path = '训练1/train_both_his2.txt'\n",
    "data = pd.read_csv(file_path)\n",
    "data['apply_date'] = pd.to_datetime(data['apply_date'])\n",
    "\n",
    "# 定义 merchant_id\n",
    "merchant_id_to_find = 934378057859389\n",
    "\n",
    "# 找到指定 merchant_id 的 apply_date\n",
    "merchant_apply_date = data.loc[data['merchant_id'] == merchant_id_to_find, 'apply_date'].max()\n",
    "\n",
    "# 加载流水数据\n",
    "clean_data = pd.read_csv('流水数据/clean.txt')\n",
    "clean_data['pt'] = pd.to_datetime(clean_data['pt'], format='%Y%m%d')\n",
    "\n",
    "# 计算申请日期的前半年范围\n",
    "start_date = merchant_apply_date - timedelta(days=180)\n",
    "\n",
    "# 筛选流水记录\n",
    "merchant_records = clean_data[clean_data['merchant_id'] == merchant_id_to_find]\n",
    "valid_records = merchant_records[(merchant_records['pt'] >= start_date) & (merchant_records['pt'] <= merchant_apply_date)]\n",
    "\n",
    "print(f\"merchant_id: {merchant_id_to_find}\")\n",
    "print(f\"最晚申请日期: {merchant_apply_date}\")\n",
    "print(f\"有效日期开始: {start_date}\")\n",
    "print(f\"符合条件的流水记录数: {len(valid_records)}\")\n",
    "print(f\"总流水记录数: {len(merchant_records)}\")\n",
    "print(\"符合条件的记录详情:\")\n",
    "print(valid_records[['pt', 'paid_amount']])  # 简化输出，仅显示日期和支付金额\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在文件 训练1/train_both_his2.txt 中找到的记录:\n",
      "   apply_id      merchant_id           apply_date  lend_amount  lend_period  \\\n",
      "0  52849963  934378057859389  2018-06-08 00:00:00      50000.0            3   \n",
      "\n",
      "   is_30days_overdue  industry_level1  province  store_count  \\\n",
      "0                  0                1         2            1   \n",
      "\n",
      "   his_loan_amount_all  avg_period  loan_count  overdue_count  overdue_rate  \\\n",
      "0              43000.0        12.0           1              0           0.0   \n",
      "\n",
      "   overdue_days_all  overdue_sum  \n",
      "0                 0            0  \n",
      "在文件 训练1/train_combined_with_merchant_info_with_store_count.txt 中未找到 merchant_id 为 934378057859389 的记录。\n",
      "在文件 测试1/test_both_his2.txt 中未找到 merchant_id 为 934378057859389 的记录。\n",
      "在文件 测试1/test_combined_with_merchant_info_with_store_count.txt 中未找到 merchant_id 为 934378057859389 的记录。\n",
      "在流水数据 clean.txt 中找到的记录:\n",
      "                        id         store_id      merchant_id  pay_way  \\\n",
      "657      t7895258640472291  863886432460409  934378057859389        3   \n",
      "1707     t7895258028014799  863886432460409  934378057859389        2   \n",
      "2964     t7895258640214960  863886432460409  934378057859389        2   \n",
      "3040     t7895258640863375  863886432460409  934378057859389        2   \n",
      "3695     t7895258647321939  863886432460409  934378057859389        3   \n",
      "...                    ...              ...              ...      ...   \n",
      "3418933  t7895258017329129  863886432460409  934378057859389        3   \n",
      "3420574  t7895258055657332  863886432460409  934378057859389        3   \n",
      "3421592  t7895258080842271  863886432460409  934378057859389        3   \n",
      "3421750  t7895258082403788  863886432460409  934378057859389        2   \n",
      "3421859  t7895258083351316  863886432460409  934378057859389        3   \n",
      "\n",
      "         sub_pay_way  paid_amount  bankcard_credit  bankcard_debit  \\\n",
      "657                1         5200                0            5200   \n",
      "1707               1         2100                0               0   \n",
      "2964               1         2800                0               0   \n",
      "3040               1         2200                0               0   \n",
      "3695               1         1300                0            1300   \n",
      "...              ...          ...              ...             ...   \n",
      "3418933            1         1300                0               0   \n",
      "3420574            1         1300                0            1300   \n",
      "3421592            1         1100                0               0   \n",
      "3421750            1         1700                0               0   \n",
      "3421859            1         1600                0            1600   \n",
      "\n",
      "         wallet_weixin  wallet_alipay  wallet_alipay_finance  alipay_huabei  \\\n",
      "657                  0              0                      0              0   \n",
      "1707                 0              0                      0           2100   \n",
      "2964                 0           2800                      0              0   \n",
      "3040                 0              0                      0           2200   \n",
      "3695                 0              0                      0              0   \n",
      "...                ...            ...                    ...            ...   \n",
      "3418933           1300              0                      0              0   \n",
      "3420574              0              0                      0              0   \n",
      "3421592           1100              0                      0              0   \n",
      "3421750              0              0                      0           1700   \n",
      "3421859              0              0                      0              0   \n",
      "\n",
      "         alipay_point        pt  \n",
      "657                 0  20180422  \n",
      "1707                0  20180422  \n",
      "2964                0  20180422  \n",
      "3040                0  20180422  \n",
      "3695                0  20180422  \n",
      "...               ...       ...  \n",
      "3418933             0  20180414  \n",
      "3420574             0  20180417  \n",
      "3421592             0  20180418  \n",
      "3421750             0  20180418  \n",
      "3421859             0  20180418  \n",
      "\n",
      "[4031 rows x 14 columns]\n",
      "该 merchant_id 934378057859389 的流水记录日期范围：从 20180401 到 20180615\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 定义 merchant_id\n",
    "merchant_id_to_find = 934378057859389\n",
    "\n",
    "# 定义文件路径列表\n",
    "file_paths = [\n",
    "    '训练1/train_both_his2.txt',\n",
    "    '训练1/train_combined_with_merchant_info_with_store_count.txt',\n",
    "    '测试1/test_both_his2.txt',\n",
    "    '测试1/test_combined_with_merchant_info_with_store_count.txt'\n",
    "]\n",
    "\n",
    "# 循环遍历文件列表，查找特定 merchant_id 的记录\n",
    "for path in file_paths:\n",
    "    data = pd.read_csv(path)\n",
    "    # 筛选出特定 merchant_id 的记录\n",
    "    filtered_data = data[data['merchant_id'] == merchant_id_to_find]\n",
    "    if not filtered_data.empty:\n",
    "        print(f\"在文件 {path} 中找到的记录:\")\n",
    "        print(filtered_data)\n",
    "    else:\n",
    "        print(f\"在文件 {path} 中未找到 merchant_id 为 {merchant_id_to_find} 的记录。\")\n",
    "\n",
    "# 加载流水数据\n",
    "clean_data = pd.read_csv('流水数据/clean.txt')\n",
    "\n",
    "# 在流水数据中查找特定 merchant_id 的记录\n",
    "clean_filtered = clean_data[clean_data['merchant_id'] == merchant_id_to_find]\n",
    "if not clean_filtered.empty:\n",
    "    print(\"在流水数据 clean.txt 中找到的记录:\")\n",
    "    print(clean_filtered)\n",
    "    # 输出该 merchant_id 对应的 pt 的最小和最大日期\n",
    "    pt_min = clean_filtered['pt'].min()\n",
    "    pt_max = clean_filtered['pt'].max()\n",
    "    print(f\"该 merchant_id {merchant_id_to_find} 的流水记录日期范围：从 {pt_min} 到 {pt_max}\")\n",
    "else:\n",
    "    print(f\"在流水数据 clean.txt 中未找到 merchant_id 为 {merchant_id_to_find} 的记录。\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 根据每个merchant_id的贷款申请日期，只保留之前的流水记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始流水数据记录数：3422391\n",
      "保留的流水数据记录数：2210268\n",
      "删除的流水记录数：1290793\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# 定义文件路径列表\n",
    "file_paths = [\n",
    "    '训练1/train_both_his2.txt',\n",
    "    '训练1/train_combined_with_merchant_info_with_store_count.txt',\n",
    "    '测试1/test_both_his2.txt',\n",
    "    '测试1/test_combined_with_merchant_info_with_store_count.txt'\n",
    "]\n",
    "\n",
    "# 合并所有文件中的 merchant_id 和 apply_date\n",
    "all_data = pd.DataFrame()\n",
    "for path in file_paths:\n",
    "    data = pd.read_csv(path, usecols=['merchant_id', 'apply_date'])\n",
    "    all_data = pd.concat([all_data, data], ignore_index=True)\n",
    "\n",
    "# 去除重复项，并转换 apply_date 为 datetime 类型\n",
    "all_data['apply_date'] = pd.to_datetime(all_data['apply_date'], errors='coerce')\n",
    "unique_data = all_data.drop_duplicates()\n",
    "\n",
    "# 加载流水数据并转换日期格式\n",
    "clean_data = pd.read_csv('流水数据/clean.txt')\n",
    "clean_data['pt'] = pd.to_datetime(clean_data['pt'], format='%Y%m%d')\n",
    "\n",
    "# 准备筛选后的数据容器\n",
    "filtered_clean_data = pd.DataFrame()\n",
    "\n",
    "# 统计删除的记录数\n",
    "deleted_records = 0\n",
    "\n",
    "# 筛选出 pt 日期早于 apply_date 半年之内的记录\n",
    "for _, row in unique_data.iterrows():\n",
    "    merchant_id = row['merchant_id']\n",
    "    apply_date = row['apply_date']\n",
    "    start_date = apply_date - timedelta(days=180)  # 计算半年前的日期\n",
    "    \n",
    "    # 获取该 merchant_id 的所有流水记录\n",
    "    merchant_records = clean_data[clean_data['merchant_id'] == merchant_id]\n",
    "    \n",
    "    # 筛选出 pt 日期在半年之内的记录\n",
    "    valid_records = merchant_records[(merchant_records['pt'] >= start_date) & (merchant_records['pt'] < apply_date)]\n",
    "    filtered_clean_data = pd.concat([filtered_clean_data, valid_records], ignore_index=True)\n",
    "    \n",
    "    # 计算删除的记录数\n",
    "    deleted_records += (len(merchant_records) - len(valid_records))\n",
    "\n",
    "# 保存筛选后的数据到新文件 clean1.txt\n",
    "filtered_clean_data.to_csv('流水数据/clean1.txt', index=False)\n",
    "\n",
    "# 输出必要的数据规模信息\n",
    "original_size = len(clean_data)\n",
    "new_size = len(filtered_clean_data)\n",
    "print(f\"原始流水数据记录数：{original_size}\")\n",
    "print(f\"保留的流水数据记录数：{new_size}\")\n",
    "print(f\"删除的流水记录数：{deleted_records}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_both_his2.txt: Total Merchant IDs: 163, Missing in clean.txt: 0\n",
      "train_combined_with_merchant_info_with_store_count.txt: Total Merchant IDs: 893, Missing in clean.txt: 0\n",
      "test_both_his2.txt: Total Merchant IDs: 65, Missing in clean.txt: 0\n",
      "test_combined_with_merchant_info_with_store_count.txt: Total Merchant IDs: 396, Missing in clean.txt: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 文件路径\n",
    "train_both_path = '训练1/train_both_his2.txt'\n",
    "train_combined_path = '训练1/train_combined_with_merchant_info_with_store_count.txt'\n",
    "test_both_path = '测试1/test_both_his2.txt'\n",
    "test_combined_path = '测试1/test_combined_with_merchant_info_with_store_count.txt'\n",
    "clean_data_path = '流水数据/clean1.txt'\n",
    "\n",
    "# 读取流水数据中的 merchant_id\n",
    "clean_data = pd.read_csv(clean_data_path)\n",
    "clean_merchant_ids = set(clean_data['merchant_id'].unique())\n",
    "\n",
    "# 读取并检查文件中的 merchant_id\n",
    "def check_merchant_ids(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    merchant_ids = set(data['merchant_id'].unique())\n",
    "    total_ids = len(merchant_ids)\n",
    "    missing_ids = merchant_ids - clean_merchant_ids\n",
    "    missing_count = len(missing_ids)\n",
    "    return total_ids, missing_count\n",
    "\n",
    "# 检查每个文件\n",
    "train_both_total, train_both_missing = check_merchant_ids(train_both_path)\n",
    "train_combined_total, train_combined_missing = check_merchant_ids(train_combined_path)\n",
    "test_both_total, test_both_missing = check_merchant_ids(test_both_path)\n",
    "test_combined_total, test_combined_missing = check_merchant_ids(test_combined_path)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"train_both_his2.txt: Total Merchant IDs: {train_both_total}, Missing in clean.txt: {train_both_missing}\")\n",
    "print(f\"train_combined_with_merchant_info_with_store_count.txt: Total Merchant IDs: {train_combined_total}, Missing in clean.txt: {train_combined_missing}\")\n",
    "print(f\"test_both_his2.txt: Total Merchant IDs: {test_both_total}, Missing in clean.txt: {test_both_missing}\")\n",
    "print(f\"test_combined_with_merchant_info_with_store_count.txt: Total Merchant IDs: {test_combined_total}, Missing in clean.txt: {test_combined_missing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "流水数据 'clean.txt' 中不同的 merchant_id 数量: 1507\n",
      "四个文件中不同的 merchant_id 总数: 1507\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 文件路径\n",
    "clean_data_path = '流水数据/clean1.txt'\n",
    "train_both_path = '训练1/train_both_his2.txt'\n",
    "train_combined_path = '训练1/train_combined_with_merchant_info_with_store_count.txt'\n",
    "test_both_path = '测试1/test_both_his2.txt'\n",
    "test_combined_path = '测试1/test_combined_with_merchant_info_with_store_count.txt'\n",
    "\n",
    "# 读取流水数据中的 merchant_id\n",
    "clean_data = pd.read_csv(clean_data_path)\n",
    "clean_merchant_ids = set(clean_data['merchant_id'].unique())\n",
    "print(f\"流水数据 'clean1.txt' 中不同的 merchant_id 数量: {len(clean_merchant_ids)}\")\n",
    "\n",
    "# 读取并汇总所有文件中的 merchant_id\n",
    "files = [train_both_path, train_combined_path, test_both_path, test_combined_path]\n",
    "all_merchant_ids = set()\n",
    "\n",
    "for file in files:\n",
    "    data = pd.read_csv(file)\n",
    "    all_merchant_ids.update(data['merchant_id'].unique())\n",
    "\n",
    "print(f\"四个文件中不同的 merchant_id 总数: {len(all_merchant_ids)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、 对经过筛选的流水记录增加avg_discount,avg_paid,avg_order,avg_balance,avg_advance五个字段"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   avg_balance: 商户储蓄卡、微信余额、支付宝余额、支付宝余额宝的总支付金额占总支付金额的比例（不预支组）"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  商户信用卡、花呗、集分宝的总支付金额占总支付金额的比例（预支组）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已保存，包含每个商户的平均每日支付金额、红包金额、订单数、balance_rate和advance_rate。\n",
      "实际支付总和小于已支付金额的订单个数: 7520\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载数据\n",
    "data_path = '流水数据/clean1.txt'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# 转换 pt 字段为日期格式（假设 pt 是格式如 '2018-04-22' 的日期表示）\n",
    "data['date'] = pd.to_datetime(data['pt'], format='%Y-%m-%d')\n",
    "\n",
    "# 定义涉及到的不同字段组\n",
    "payment_columns = [\n",
    "    'bankcard_credit', 'bankcard_debit', 'wallet_weixin',\n",
    "    'wallet_alipay', 'wallet_alipay_finance', 'alipay_huabei', 'alipay_point'\n",
    "]\n",
    "balance_fields = ['bankcard_debit', 'wallet_weixin', 'wallet_alipay', 'wallet_alipay_finance']\n",
    "advance_fields = ['bankcard_credit', 'alipay_huabei', 'alipay_point']\n",
    "\n",
    "# 确保所有涉及运算的字段都是数值类型\n",
    "data[payment_columns + ['paid_amount']] = data[payment_columns + ['paid_amount']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 计算每个订单的实际支付总和并检测支付不足的订单\n",
    "data['real_sum'] = data[payment_columns].sum(axis=1)\n",
    "underpaid_count = (data['real_sum'] < data['paid_amount']).sum()\n",
    "data['discount'] = data.apply(lambda x: x['real_sum'] - x['paid_amount'] if x['real_sum'] >= x['paid_amount'] else 0, axis=1)\n",
    "\n",
    "# 计算订单统计信息\n",
    "daily_order_counts = data.groupby(['merchant_id', 'date'])['id'].nunique().reset_index(name='order_count')\n",
    "avg_order_per_merchant = daily_order_counts.groupby('merchant_id')['order_count'].mean().reset_index(name='avg_order')\n",
    "\n",
    "# 计算余额和预付信息\n",
    "data['pay_balance'] = data[balance_fields].sum(axis=1)\n",
    "data['balance_rate'] = data['pay_balance'] / data['paid_amount']\n",
    "data['pay_advance'] = data[advance_fields].sum(axis=1)\n",
    "data['advance_rate'] = data['pay_advance'] / data['paid_amount']\n",
    "\n",
    "# 分组计算每个merchant_id的各类统计信息\n",
    "grouped_discount = data.groupby(['merchant_id', 'date'])['discount'].sum().reset_index()\n",
    "avg_discount = grouped_discount.groupby('merchant_id')['discount'].mean().reset_index(name='avg_discount')\n",
    "grouped_data = data.groupby('merchant_id').agg(avg_balance=('balance_rate', 'mean'), avg_advance=('advance_rate', 'mean')).reset_index()\n",
    "\n",
    "# 保存结果到新文件\n",
    "avg_paid = data.groupby(['merchant_id', 'date'])['paid_amount'].sum().reset_index(name='paid_amount_sum').groupby('merchant_id')['paid_amount_sum'].mean().reset_index(name='avg_paid')\n",
    "avg_paid.to_csv('流水数据/avg_paid.txt', index=False)\n",
    "avg_discount.to_csv('流水数据/avg_discount.txt', index=False)\n",
    "grouped_data.to_csv('流水数据/rate.txt', index=False, sep=',')\n",
    "avg_order_per_merchant.to_csv('流水数据/order.txt', index=False, sep=',')\n",
    "\n",
    "# 输出\n",
    "print(f\"文件已保存，包含每个商户的平均每日支付金额、红包金额、订单数、balance_rate和advance_rate。\")\n",
    "print(f\"实际支付总和小于已支付金额的订单个数: {underpaid_count}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1、 形成一个只有merchant_id、avg_discount、avg_paid、avg_order、avg_balance、avg_advance六个字段的文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始 avg_paid.txt 文件的维度 (行数, 列数): (1507, 2)\n",
      "合并后 avg_paid.txt 文件的维度 (行数, 列数): (1507, 6)\n",
      "数据已更新并保存到 avg_paid_updated.txt。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载数据\n",
    "avg_paid = pd.read_csv('流水数据/avg_paid.txt')\n",
    "avg_discount = pd.read_csv('流水数据/avg_discount.txt')\n",
    "rate = pd.read_csv('流水数据/rate.txt')\n",
    "order = pd.read_csv('流水数据/order.txt')\n",
    "\n",
    "# 打印原始 avg_paid 的维度 (行数, 列数)\n",
    "original_shape = avg_paid.shape\n",
    "print(f\"原始 avg_paid.txt 文件的维度 (行数, 列数): {original_shape}\")\n",
    "\n",
    "# 合并 avg_discount\n",
    "avg_paid = avg_paid.merge(avg_discount, on='merchant_id', how='left')\n",
    "\n",
    "# 合并 rate，包含 avg_balance 和 avg_advance\n",
    "avg_paid = avg_paid.merge(rate, on='merchant_id', how='left')\n",
    "\n",
    "# 合并 order，包含 avg_order\n",
    "avg_paid = avg_paid.merge(order, on='merchant_id', how='left')\n",
    "\n",
    "# 打印合并后 avg_paid 的维度 (行数, 列数)\n",
    "merged_shape = avg_paid.shape\n",
    "print(f\"合并后 avg_paid.txt 文件的维度 (行数, 列数): {merged_shape}\")\n",
    "\n",
    "# 保存合并后的数据到新文件，或覆盖原文件\n",
    "avg_paid.to_csv('流水数据/avg_paid_updated.txt', index=False)\n",
    "\n",
    "print(\"数据已更新并保存到 avg_paid_updated.txt。\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2、 根据merchant_id的对应关系将来自流水数据的五个新特征合并到训练和测试文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 训练1/train_both_his2.txt 中的所有 merchant_id 都在 avg_paid_updated.txt 中找到了。\n",
      "文件 训练1/train_combined_with_merchant_info_with_store_count.txt 中的所有 merchant_id 都在 avg_paid_updated.txt 中找到了。\n",
      "文件 测试1/test_both_his2.txt 中的所有 merchant_id 都在 avg_paid_updated.txt 中找到了。\n",
      "文件 测试1/test_combined_with_merchant_info_with_store_count.txt 中的所有 merchant_id 都在 avg_paid_updated.txt 中找到了。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 定义文件路径列表\n",
    "file_paths = [\n",
    "    '训练1/train_both_his2.txt',\n",
    "    '训练1/train_combined_with_merchant_info_with_store_count.txt',\n",
    "    '测试1/test_both_his2.txt',\n",
    "    '测试1/test_combined_with_merchant_info_with_store_count.txt'\n",
    "]\n",
    "\n",
    "# 加载 avg_paid_updated.txt\n",
    "avg_paid_updated = pd.read_csv('流水数据/avg_paid_updated.txt')\n",
    "avg_paid_ids = set(avg_paid_updated['merchant_id'])\n",
    "\n",
    "# 遍历每个文件并检查其中的 merchant_id 是否都在 avg_paid_updated.txt 中\n",
    "for path in file_paths:\n",
    "    data = pd.read_csv(path)\n",
    "    missing_ids = set(data['merchant_id']) - avg_paid_ids\n",
    "    if missing_ids:\n",
    "        print(f\"在文件 {path} 中，以下 merchant_id 在 avg_paid_updated.txt 中未找到:\", missing_ids)\n",
    "    else:\n",
    "        print(f\"文件 {path} 中的所有 merchant_id 都在 avg_paid_updated.txt 中找到了。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始 训练1/train_both_his2.txt 文件的维度 (行数, 列数): (164, 16)\n",
      "合并后的 训练1/train_both_his2.txt 文件的维度 (行数, 列数): (164, 21)\n",
      "更新后的数据已保存到 训练1/train_both_his2_updated.txt\n",
      "\n",
      "原始 训练1/train_combined_with_merchant_info_with_store_count.txt 文件的维度 (行数, 列数): (910, 9)\n",
      "合并后的 训练1/train_combined_with_merchant_info_with_store_count.txt 文件的维度 (行数, 列数): (910, 14)\n",
      "更新后的数据已保存到 训练1/train_combined_with_merchant_info_with_store_count_updated.txt\n",
      "\n",
      "原始 测试1/test_both_his2.txt 文件的维度 (行数, 列数): (65, 15)\n",
      "合并后的 测试1/test_both_his2.txt 文件的维度 (行数, 列数): (65, 20)\n",
      "更新后的数据已保存到 测试1/test_both_his2_updated.txt\n",
      "\n",
      "原始 测试1/test_combined_with_merchant_info_with_store_count.txt 文件的维度 (行数, 列数): (400, 8)\n",
      "合并后的 测试1/test_combined_with_merchant_info_with_store_count.txt 文件的维度 (行数, 列数): (400, 13)\n",
      "更新后的数据已保存到 测试1/test_combined_with_merchant_info_with_store_count_updated.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载 avg_paid_updated 数据\n",
    "avg_paid_updated = pd.read_csv('流水数据/avg_paid_updated.txt')\n",
    "\n",
    "# 定义文件路径列表\n",
    "file_paths = [\n",
    "    '训练1/train_both_his2.txt',\n",
    "    '训练1/train_combined_with_merchant_info_with_store_count.txt',\n",
    "    '测试1/test_both_his2.txt',\n",
    "    '测试1/test_combined_with_merchant_info_with_store_count.txt'\n",
    "]\n",
    "\n",
    "# 对每个文件进行处理\n",
    "for path in file_paths:\n",
    "    # 加载当前文件\n",
    "    data = pd.read_csv(path)\n",
    "    print(f\"原始 {path} 文件的维度 (行数, 列数): {data.shape}\")\n",
    "\n",
    "    # 合并 avg_paid 更新的信息\n",
    "    merged_data = pd.merge(data, avg_paid_updated, on='merchant_id', how='left')\n",
    "\n",
    "    # 打印合并后的文件规模\n",
    "    print(f\"合并后的 {path} 文件的维度 (行数, 列数): {merged_data.shape}\")\n",
    "\n",
    "    # 保存新的合并文件\n",
    "    new_path = path.replace('.txt', '_updated.txt')\n",
    "    merged_data.to_csv(new_path, index=False)\n",
    "    print(f\"更新后的数据已保存到 {new_path}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
